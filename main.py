import telebot
import requests
import os
import re
from bs4 import BeautifulSoup

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–µ—Ü. –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –ò–ò
os.system('pip install duckduckgo_search')
from duckduckgo_search import DDGS

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916" 
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_links():
    if not os.path.exists(DB_FILE): return []
    with open(DB_FILE, "r") as f: return f.read().splitlines()

def save_posted_link(link):
    with open(DB_FILE, "a") as f: f.write(link + "\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']): s.decompose()
        text = " ".join([p.get_text() for p in soup.find_all('p')])
        return text[:3000]
    except:
        return None

def rewrite_text(title, content):
    prompt = (
        f"–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è –¢–µ–ª–µ–≥—Ä–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–∏.\n"
        f"–ù–û–í–û–°–¢–¨: {title}\n"
        f"–¢–ï–ö–°–¢: {content}\n\n"
        f"–ü–†–ê–í–ò–õ–ê:\n"
        f"1. –°–Ω–∞—á–∞–ª–∞ –∂–∏—Ä–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∫—Ä—É—Ç—ã–º —Å–º–∞–π–ª–æ–º. üî•\n"
        f"2. –ö–æ—Ä–æ—Ç–∫–æ —Å—É—Ç—å (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).\n"
        f"3. –°–ø–∏—Å–æ–∫ —Ñ–∞–∫—Ç–æ–≤ (3 –ø—É–Ω–∫—Ç–∞, –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –°–í–û–ô –∂–∏—Ä–Ω—ã–π —Å–º–∞–π–ª: ‚ö°Ô∏è, üíé, üöÄ).\n"
        f"4. –ò—Ç–æ–≥ –æ–¥–Ω–∏–º –∫–æ—Ä–æ—Ç–∫–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º. –ë–ï–ó –ú–ù–û–ì–û–¢–û–ß–ò–ô.\n"
        f"–ù–ò–ö–ê–ö–ò–• —Å—Å—ã–ª–æ–∫ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤!"
    )
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DuckDuckGo AI (–º–æ–¥–µ–ª—å GPT-4o-mini) - –æ–Ω–∞ –Ω–µ –æ–±—Ä—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç
        with DDGS() as ddgs:
            results = ddgs.chat(prompt, model='gpt-4o-mini')
            res = results.strip()
            return re.sub(r'\.{2,}|‚Ä¶$', '.', res)
    except:
        return f"<b>{title}</b>\n\n{content[:500]}."

def run():
    url = f"https://newsapi.org/v2/everything?q=(IT OR —Ö–∞–π–ø OR –Ω–µ–π—Ä–æ—Å–µ—Ç–∏)&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        articles = requests.get(url).json().get('articles', [])
    except:
        return

    posted = get_posted_links()

    for art in articles:
        link = art['url']
        if link in posted: continue
        
        raw_text = get_full_article(link)
        content = raw_text if (raw_text and len(raw_text) > 400) else art.get('description', "")
        
        if not content: continue

        final_post = rewrite_text(art['title'], content)
        caption = f"{final_post}\n\nüóû <b>–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ <a href='https://t.me/SUP_V_BotK'>SUP_V_BotK</a></b>"
        
        try:
            if art.get('urlToImage'):
                bot.send_photo(CHANNEL_ID, art['urlToImage'], caption=caption, parse_mode='HTML')
            else:
                bot.send_message(CHANNEL_ID, caption, parse_mode='HTML')
            save_posted_link(link)
            break
        except:
            continue

if __name__ == "__main__":
    run()

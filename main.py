import os
import telebot
import requests
import re
import random
from bs4 import BeautifulSoup
import g4f

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916" 
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_data():
    if not os.path.exists(DB_FILE): return set()
    with open(DB_FILE, "r", encoding="utf-8") as f:
        return set(f.read().splitlines())

def save_posted_data(link, title):
    clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
    with open(DB_FILE, "a", encoding="utf-8") as f:
        f.write(f"{link}\n{clean_title}\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']): s.decompose()
        text = " ".join([p.get_text() for p in soup.find_all('p')])
        return text[:3000]
    except:
        return None

def rewrite_text(title, content):
    prompt = (
        f"–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –¢–ì-—Ä–µ–¥–∞–∫—Ç–æ—Ä. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–¥–µ–ª–∞—Ç—å –ö–†–ê–¢–ö–ò–ô –ü–ï–†–ï–°–ö–ê–ó.\n\n"
        f"–ù–û–í–û–°–¢–¨: {title}\n"
        f"–¢–ï–ö–°–¢: {content}\n\n"
        f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n"
        f"1. –ù–∞–ø–∏—à–∏ –ñ–ò–†–ù–´–ô –∑–∞–≥–æ–ª–æ–≤–æ–∫ üî•.\n"
        f"2. –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ —Å—É—Ç–∏ (–º–∞–∫—Å–∏–º—É–º 4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). –î–µ–ª–∏ –Ω–∞ –∞–±–∑–∞—Ü—ã.\n"
        f"3. –í—ã–¥–µ–ª–∏ 3 –≥–ª–∞–≤–Ω—ã—Ö —Ñ–∞–∫—Ç–∞ —Ç–æ—á–∫–∞–º–∏ (‚ö°Ô∏è, üöÄ, üíé).\n"
        f"4. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –û–î–ò–ù –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–π –∏—Ç–æ–≥.\n\n"
        f"–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:\n"
        f"- –ü–ò–®–ò –ö–û–†–û–¢–ö–û (–¥–æ 800 –∑–Ω–∞–∫–æ–≤), —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç –Ω–µ –æ–±–æ—Ä–≤–∞–ª—Å—è!\n"
        f"- –¢–µ–∫—Å—Ç –æ–±—è–∑–∞–Ω –±—ã—Ç—å –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–º. –ù–∏–∫–∞–∫–∏—Ö –º–Ω–æ–≥–æ—Ç–æ—á–∏–π –≤ –∫–æ–Ω—Ü–µ!\n"
        f"- –ï—Å–ª–∏ –Ω–µ —É—Å–ø–µ–≤–∞–µ—à—å –¥–æ–ø–∏—Å–∞—Ç—å ‚Äî –ª—É—á—à–µ —Å–æ–∫—Ä–∞—Ç–∏ –¥–µ—Ç–∞–ª–∏, –Ω–æ –ø–æ—Å—Ç–∞–≤—å —Ç–æ—á–∫—É."
    )
    try:
        response = g4f.ChatCompletion.create(
            model=g4f.models.gpt_4o,
            messages=[{"role": "user", "content": prompt}],
            provider=g4f.Provider.Blackbox
        )
        text = response.strip()
        
        # –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ü–µ –≤—Å—ë —Ä–∞–≤–Ω–æ –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ ‚Äî —Ä–µ–∂–µ–º –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ç–æ—á–∫–∏
        if text.endswith('...') or text.endswith('‚Ä¶'):
            last_dot = text.rfind('.')
            if last_dot != -1:
                text = text[:last_dot + 1]
        
        return text
    except:
        return f"üî• <b>{title}</b>\n\n{content[:400]}..."

def run():
    url = f"https://newsapi.org/v2/everything?q=(IT OR –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ OR —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        articles = requests.get(url).json().get('articles', [])
    except: return

    posted_data = get_posted_data()
    random.shuffle(articles)

    for art in articles:
        link = art['url']
        title = art['title']
        clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
        
        if link in posted_data or clean_title in posted_data: continue
        
        raw_text = get_full_article(link)
        content = raw_text if (raw_text and len(raw_text) > 400) else art.get('description', "")
        if not content: continue

        final_post = rewrite_text(title, content)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—Ä—É–±–æ–∫: –µ—Å–ª–∏ –º–µ–Ω—å—à–µ 150 —Å–∏–º–≤–æ–ª–æ–≤ –∏–ª–∏ –Ω–µ—Ç —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ ‚Äî —Å–∫–∏–ø–∞–µ–º
        if len(final_post) < 150 or not final_post.endswith(('.', '!', '?')):
            continue

        caption = f"{final_post}\n\nüóû <b>–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ <a href='https://t.me/SUP_V_BotK'>SUP_V_BotK</a></b>"
        
        try:
            if art.get('urlToImage'):
                bot.send_photo(CHANNEL_ID, art['urlToImage'], caption=caption, parse_mode='HTML')
            else:
                bot.send_message(CHANNEL_ID, caption, parse_mode='HTML')
            save_posted_data(link, title)
            break
        except: continue

if __name__ == "__main__":
    run()

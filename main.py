import telebot
import g4f
import requests
import os
import re
from bs4 import BeautifulSoup

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916" 
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_links():
    if not os.path.exists(DB_FILE): return []
    with open(DB_FILE, "r") as f: return f.read().splitlines()

def save_posted_link(link):
    with open(DB_FILE, "a") as f: f.write(link + "\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']): s.decompose()
        text = " ".join([p.get_text() for p in soup.find_all('p')])
        return text[:3500]
    except:
        return None

def rewrite_text(title, content):
    prompt = (
        f"–°–¥–µ–ª–∞–π —á–µ—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–æ–≤–æ—Å—Ç–∏. –ë–ï–ó –ú–ù–û–ì–û–¢–û–ß–ò–ô –í –ö–û–ù–¶–ï. –ë–ï–ó –û–ë–†–´–í–û–í.\n"
        f"–ù–û–í–û–°–¢–¨: {title}\n"
        f"–¢–ï–ö–°–¢: {content}\n\n"
        f"–§–û–†–ú–ê–¢:\n"
        f"1. ‚ö°Ô∏è –ñ–∏—Ä–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫.\n"
        f"2. –°—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).\n"
        f"3. –°–ø–∏—Å–æ–∫ –ì–õ–ê–í–ù–´–• —Ñ–∞–∫—Ç–æ–≤ (3-4 –ø—É–Ω–∫—Ç–∞, –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Å—Ç–∞–≤—å —Å–º–∞–π–ª: üî•, üöÄ, üìç, üíé).\n"
        f"4. –ò—Ç–æ–≥ –æ–¥–Ω–∏–º –∫–æ—Ä–æ—Ç–∫–∏–º –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º.\n\n"
        f"–ü–†–ê–í–ò–õ–ê: –ò—Å–ø–æ–ª—å–∑—É–π –º–Ω–æ–≥–æ —Å–º–∞–π–ª–∏–∫–æ–≤. –ü–∏—à–∏ –ø–æ–Ω—è—Ç–Ω–æ. –ù–µ –æ–±—Ä—ã–≤–∞–π –Ω–∞ –ø–æ–ª—É—Å–ª–æ–≤–µ!"
    )
    try:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ø–∏—Å–∫–æ–≤
        response = g4f.ChatCompletion.create(
            model=g4f.models.gpt_4o,
            messages=[{"role": "user", "content": prompt}]
        )
        res = response.strip()
        res = re.sub(r'\.{2,}|‚Ä¶$', '.', res) # –°—Ä–µ–∑–∞–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏—è
        return res
    except:
        return f"<b>{title}</b>\n\n{content[:500]}."

def run():
    url = f"https://newsapi.org/v2/everything?q=(IT OR —Ö–∞–π–ø OR –Ω–µ–π—Ä–æ—Å–µ—Ç–∏)&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        articles = requests.get(url).json().get('articles', [])
    except:
        return

    posted = get_posted_links()

    for art in articles:
        link = art['url']
        if link in posted: continue
        
        raw_text = get_full_article(link)
        content = raw_text if (raw_text and len(raw_text) > 400) else art.get('description', "")
        
        if not content: continue

        final_post = rewrite_text(art['title'], content)
        caption = f"{final_post}\n\nüóû <b>–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ <a href='https://t.me/SUP_V_BotK'>SUP_V_BotK</a></b>"
        
        try:
            if art.get('urlToImage'):
                bot.send_photo(CHANNEL_ID, art['urlToImage'], caption=caption, parse_mode='HTML')
            else:
                bot.send_message(CHANNEL_ID, caption, parse_mode='HTML')
            save_posted_link(link)
            break
        except:
            continue

if __name__ == "__main__":
    run()

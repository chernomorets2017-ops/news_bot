import os
import telebot
import requests
import re
import random
from bs4 import BeautifulSoup

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916"
OR_TOKEN = "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"
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_data():
    if not os.path.exists(DB_FILE): return set()
    with open(DB_FILE, "r", encoding="utf-8") as f:
        return set(f.read().splitlines())

def save_posted_data(link, title):
    clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
    with open(DB_FILE, "a", encoding="utf-8") as f:
        f.write(f"{link}\n{clean_title}\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']): s.decompose()
        return " ".join([p.get_text() for p in soup.find_all('p')])[:2500]
    except:
        return None

def rewrite_to_caption(title, content):
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OR_TOKEN}", "Content-Type": "application/json"}
    
    prompt = (
        f"–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –¢–ì-–∫–∞–Ω–∞–ª–∞. –ù–∞–ø–∏—à–∏ —Å–æ—á–Ω—ã–π CAPTION –¥–ª—è —Ñ–æ—Ç–æ –ø–æ —ç—Ç–æ–π –Ω–æ–≤–æ—Å—Ç–∏.\n\n"
        f"–ù–û–í–û–°–¢–¨: {title}\n"
        f"–ö–û–ù–¢–ï–ù–¢: {content[:1500]}\n\n"
        f"–°–¢–†–£–ö–¢–£–†–ê –ü–û–î–ü–ò–°–ò:\n"
        f"1. üî• –•–ê–ô–ü–û–í–´–ô –ó–ê–ì–û–õ–û–í–û–ö (–∫–∞–ø—Å–æ–º).\n"
        f"2. –°–£–¢–¨: 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∏ –¥–µ—Ä–∑–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
        f"3. –ü–û–î–†–û–ë–ù–û–°–¢–ò: 3 –≤–∞–∂–Ω—ã—Ö —Ñ–∞–∫—Ç–∞ —á–µ—Ä–µ–∑ –±—É–ª–ª–∏—Ç—ã ‚Ä¢.\n"
        f"4. –ü–†–ò–ó–´–í: –û—Å—Ç—Ä—ã–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Å–æ–≤–µ—Ç —á–∏—Ç–∞—Ç–µ–ª—é.\n"
        f"5. –•–ï–®–¢–ï–ì–ò.\n\n"
        f"–í–ê–ñ–ù–û: –ü–∏—à–∏ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤, —Ç–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–¥–ø–∏—Å–∏. –ú–∞–∫—Å–∏–º—É–º 900 –∑–Ω–∞–∫–æ–≤."
    )
    
    try:
        response = requests.post(url, headers=headers, json={
            "model": "google/gemini-flash-1.5",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.9
        }, timeout=25)
        return response.json()['choices'][0]['message']['content'].strip()
    except:
        return None

def run():
    api_url = f"https://newsapi.org/v2/everything?q=(YouTube OR TikTok OR —Å–∫–∞–Ω–¥–∞–ª OR –ß–ü OR –±–ª–æ–≥–µ—Ä OR –Ω–æ–≤–æ—Å—Ç–∏)&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        articles = requests.get(api_url).json().get('articles', [])
    except: return
    
    posted_data = get_posted_data()
    random.shuffle(articles)
    
    for art in articles:
        link, title = art['url'], art['title']
        clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
        
        if link in posted_data or clean_title in posted_data: continue
        
        content = get_full_article(link) or art.get('description', "")
        if len(content) < 300: continue
        
        caption_text = rewrite_to_caption(title, content)
        if not caption_text or len(caption_text) < 150: continue
        
        full_caption = f"{caption_text}\n\nüóû <b>–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ <a href='https://t.me/SUP_V_BotK'>SUP_V_BotK</a></b>"
        
        try:
            if art.get('urlToImage'):
                bot.send_photo(CHANNEL_ID, art['urlToImage'], caption=full_caption[:1024], parse_mode='HTML')
            else:
                bot.send_message(CHANNEL_ID, full_caption, parse_mode='HTML', disable_web_page_preview=False)
            save_posted_data(link, title)
            break
        except: continue

if __name__ == "__main__":
    run()

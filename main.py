import os
import sys

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –ø—Ä—è–º–æ –≤ —Ä–∞–Ω—Ç–∞–π–º–µ
def install_deps():
    os.system(f"{sys.executable} -m pip install duckduckgo_search pyTelegramBotAPI beautifulsoup4 requests")

try:
    from duckduckgo_search import DDGS
except ImportError:
    install_deps()
    from duckduckgo_search import DDGS

import telebot
import requests
import re
from bs4 import BeautifulSoup

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916" 
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_data():
    if not os.path.exists(DB_FILE): return set()
    with open(DB_FILE, "r", encoding="utf-8") as f:
        return set(f.read().splitlines())

def save_posted_data(link, title):
    # –û—á–∏—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç –ª–∏—à–Ω–µ–≥–æ –º—É—Å–æ—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
    with open(DB_FILE, "a", encoding="utf-8") as f:
        f.write(f"{link}\n{clean_title}\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']): s.decompose()
        text = " ".join([p.get_text() for p in soup.find_all('p')])
        return text[:4000]
    except:
        return None

def rewrite_text(title, content):
    prompt = (
        f"–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è Telegram. –°–î–ï–õ–ê–ô –ï–ì–û –ü–û–õ–ù–´–ú –ò –ó–ê–ö–û–ù–ß–ï–ù–ù–´–ú.\n"
        f"–ù–û–í–û–°–¢–¨: {title}\n"
        f"–¢–ï–ö–°–¢: {content}\n\n"
        f"–°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:\n"
        f"1. –ù–∞—á–Ω–∏ —Å –∂–∏—Ä–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Å–º–∞–π–ª–∞. üî•\n"
        f"2. –†–∞—Å—Å–∫–∞–∂–∏ —Å—É—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ (3-4 –∞–±–∑–∞—Ü–∞). –ë–ï–ó –û–ë–†–´–í–û–í.\n"
        f"3. –ò—Å–ø–æ–ª—å–∑—É–π —Å–º–∞–π–ª—ã (‚ö°Ô∏è, üöÄ, üìç, üíé) –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–æ–≤.\n"
        f"4. –í –∫–æ–Ω—Ü–µ ‚Äî –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥. –ù–ò–ö–ê–ö–ò–• –ú–ù–û–ì–û–¢–û–ß–ò–ô.\n"
        f"5. –ó–ê–ü–†–ï–¢: –ù–µ –ø–∏—à–∏ —Å—Å—ã–ª–∫–∏ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–∞–π—Ç–æ–≤."
    )
    try:
        with DDGS() as ddgs:
            results = ddgs.chat(prompt, model='gpt-4o-mini')
            # –ï—Å–ª–∏ –ò–ò –≤—Å—ë –∂–µ –±—Ä–æ—Å–∏–ª –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ ‚Äî –º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ—á–∫—É
            res = results.strip()
            if res.endswith('...') or res.endswith('‚Ä¶'):
                res = res.rsplit(' ', 1)[0] + "."
            return res
    except:
        return f"<b>{title}</b>\n\n{content[:600]}."

def run():
    url = f"https://newsapi.org/v2/everything?q=(IT OR —Ö–∞–π–ø OR –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ OR —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        articles = requests.get(url).json().get('articles', [])
    except:
        return

    posted_data = get_posted_data()

    for art in articles:
        link = art['url']
        title = art['title']
        clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –ò–õ–ò –ø–æ—Ö–æ–∂–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —É–∂–µ –±—ã–ª–∏ ‚Äî —Å–∫–∏–ø–∞–µ–º
        if link in posted_data or clean_title in posted_data:
            continue
        
        raw_text = get_full_article(link)
        content = raw_text if (raw_text and len(raw_text) > 400) else art.get('description', "")
        
        if not content or len(content) < 100: continue

        final_post = rewrite_text(title, content)
        caption = f"{final_post}\n\nüóû <b>–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ <a href='https://t.me/SUP_V_BotK'>SUP_V_BotK</a></b>"
        
        try:
            if art.get('urlToImage'):
                bot.send_photo(CHANNEL_ID, art['urlToImage'], caption=caption, parse_mode='HTML')
            else:
                bot.send_message(CHANNEL_ID, caption, parse_mode='HTML')
            
            save_posted_data(link, title)
            print(f"–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {title}")
            break # –ü—É–±–ª–∏–∫—É–µ–º –û–î–ù–£ —Å–≤–µ–∂—É—é –Ω–æ–≤–æ—Å—Ç—å –∑–∞ —Ä–∞–∑
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
            continue

if __name__ == "__main__":
    run()

import telebot
import g4f
import requests
import os
import re
from bs4 import BeautifulSoup

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916" 
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_links():
    if not os.path.exists(DB_FILE): return []
    with open(DB_FILE, "r") as f: return f.read().splitlines()

def save_posted_link(link):
    with open(DB_FILE, "a") as f: f.write(link + "\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header']): s.decompose()
        paragraphs = soup.find_all('p')
        full_text = " ".join([p.get_text() for p in paragraphs])
        return full_text[:5000]
    except:
        return None

def get_news():
    query = "(IT OR —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ OR –≥–∞–¥–∂–µ—Ç—ã OR –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ OR –∏–≥—Ä—ã OR –∫—Ä–∏–ø—Ç–∞ OR —à–æ—É–±–∏–∑ OR —Ö–∞–π–ø OR –±–ª–æ–≥–µ—Ä—ã OR –º–µ–º—ã)"
    url = f"https://newsapi.org/v2/everything?q={query}&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    try:
        res = requests.get(url).json()
        return res.get('articles', [])
    except:
        return []

def rewrite_text(title, full_content):
    prompt = (
        f"–¢—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –∞–¥–º–∏–Ω —Ö–∞–π–ø–æ–≤–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞. –ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –ø–æ —Å—Ç–∞—Ç—å–µ.\n\n"
        f"–ó–ê–ì–û–õ–û–í–û–ö: {title}\n"
        f"–¢–ï–ö–°–¢:\n{full_content}\n\n"
        f"–ó–ê–î–ê–ß–ê:\n"
        f"1. –°–¥–µ–ª–∞–π –ö–†–£–¢–û–ô –ñ–ò–†–ù–´–ô –ó–ê–ì–û–õ–û–í–û–ö.\n"
        f"2. –ù–∞–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π, —Å–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç (800-1200 –∑–Ω–∞–∫–æ–≤). –ù–µ —Å–æ–∫—Ä–∞—â–∞–π —Å—É—Ç—å!\n"
        f"3. –ò—Å–ø–æ–ª—å–∑—É–π –∞–±–∑–∞—Ü—ã –∏ —Å–ø–∏—Å–∫–∏.\n"
        f"4. –°–¢–ò–ö–ï–†–´ –ò –≠–ú–û–î–ó–ò: –î–æ–±–∞–≤–ª—è–π –∏—Ö —á–∞—Å—Ç–æ! –í—Å—Ç–∞–≤–ª—è–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–æ —Å–º—ã—Å–ª—É —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫ –∏ –≤ –∫–æ–Ω—Ü–µ –∞–±–∑–∞—Ü–µ–≤. üöÄüî•üíé\n"
        f"5. –°—Ç–∏–ª—å: –º–æ–ª–æ–¥–µ–∂–Ω—ã–π, –∏—Ä–æ–Ω–∏—á–Ω—ã–π, —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π.\n"
        f"6. –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å –ø—Ä–∏–∑—ã–≤ –∫ –æ–±—Å—É–∂–¥–µ–Ω–∏—é –∏–ª–∏ –¥–µ—Ä–∑–∫–∏–π –≤–æ–ø—Ä–æ—Å."
    )
    try:
        response = g4f.ChatCompletion.create(model="gpt-3.5-turbo", messages=[{"role": "user", "content": prompt}])
        return re.sub(r'http[s]?://\S+', '', response)
    except:
        return f"<b>{title.upper()}</b>\n\n{full_content[:500]}..."

def run():
    posted_links = get_posted_links()
    articles = get_news()
    if not articles: return

    for art in articles:
        link = art['url']
        if link in posted_links: continue
        
        full_content = get_full_article(link)
        if not full_content or len(full_content) < 400:
            full_content = art.get('description', "")

        if len(full_content) < 50: continue

        text = rewrite_text(art['title'], full_content)
        img = art.get('urlToImage')
        
        caption = f"{text}\n\nüìç <a href='{link}'>–ò–°–¢–û–ß–ù–ò–ö</a>\nüóû <b>–ü–æ–¥–ø–∏—à–∏—Å—å –Ω–∞ <a href='https://t.me/SUP_V_BotK'>SUP_V_BotK</a></b>"
        
        try:
            if img:
                bot.send_photo(CHANNEL_ID, img, caption=caption, parse_mode='HTML')
            else:
                bot.send_message(CHANNEL_ID, caption, parse_mode='HTML')
            save_posted_link(link)
            break 
        except:
            continue

if __name__ == "__main__":
    run()

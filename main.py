import os
import telebot
import requests
import re
import random
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS

BOT_TOKEN = "8546746980:AAF3z5K85WaBMC-SKTSTN5Tx_dXxXyZXIoQ"
NEWS_API_KEY = "E16b35592a2147989d80d46457d4f916" 
CHANNEL_ID = "@SUP_V_BotK"
DB_FILE = "last_links.txt"

bot = telebot.TeleBot(BOT_TOKEN)

def get_posted_data():
    if not os.path.exists(DB_FILE): return set()
    with open(DB_FILE, "r", encoding="utf-8") as f:
        return set(f.read().splitlines())

def save_posted_data(link, title):
    clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
    with open(DB_FILE, "a", encoding="utf-8") as f:
        f.write(f"{link}\n{clean_title}\n")

def get_full_article(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']): s.decompose()
        text = " ".join([p.get_text() for p in soup.find_all('p')])
        return text[:3800]
    except:
        return None

def rewrite_text(title, content):
    CORE_LOGIC = (
        f"–ù–∞–ø–∏—à–∏ —Ö–∞–π–ø–æ–≤—ã–π –ø–æ—Å—Ç –¥–ª—è Telegram –æ —Å–æ–±—ã—Ç–∏—è—Ö –≤ —Å–æ—Ü—Å–µ—Ç—è—Ö –∏ –º–∏—Ä–µ.\n\n"
        f"–¢–ï–ú–ê: {title}\n"
        f"–î–ê–ù–ù–´–ï: {content}\n\n"
        f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n"
        f"1. –°–¥–µ–ª–∞–π –æ—á–µ–Ω—å –∂–∏—Ä–Ω—ã–π –∏ –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å —ç–º–æ–¥–∑–∏.\n"
        f"2. –ü–æ–¥—Ä–æ–±–Ω–æ —Ä–∞–∑–±–µ—Ä–∏ —Å–∏—Ç—É–∞—Ü–∏—é: —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å –≤ —Å–æ—Ü—Å–µ—Ç—è—Ö (VK, YouTube, TikTok, Telegram), —á—Ç–æ –≥–æ–≤–æ—Ä—è—Ç –±–ª–æ–≥–µ—Ä—ã, –∫–∞–∫–∏–µ —Å–∫–∞–Ω–¥–∞–ª—ã –∏–ª–∏ –∏–Ω—Å–∞–π–¥—ã.\n"
        f"3. –ï—Å–ª–∏ —ç—Ç–æ –ß–ü, –ø–æ–ª–∏—Ç–∏–∫–∞ –∏–ª–∏ –ø–æ–≥–æ–¥–∞ ‚Äî –ø–∏—à–∏ –∂–µ—Å—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.\n"
        f"4. –ü–∏—à–∏ –¥–ª–∏–Ω–Ω–æ (1500-2500 –∑–Ω–∞–∫–æ–≤), –∏—Å–ø–æ–ª—å–∑—É–π –∞–±–∑–∞—Ü—ã.\n"
        f"5. –ù–∏–∫–∞–∫–∏—Ö —Å–ø–∏—Å–∫–æ–≤, —Ç–æ–ª—å–∫–æ –∂–∏–≤–æ–π –∞–≤—Ç–æ—Ä—Å–∫–∏–π —Ç–µ–∫—Å—Ç.\n"
        f"6. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–∫–æ–Ω—á–∏ –º—ã—Å–ª—å –∏ –¥–æ–±–∞–≤—å —Ö–∞–π–ø–æ–≤—ã–µ —Ö–µ—à—Ç–µ–≥–∏."
    )
    try:
        with DDGS() as ddgs:
            response = ddgs.chat(CORE_LOGIC, model='gpt-4o-mini')
            text = response.strip()
            text = re.sub(r'^(–í–æ—Ç|–ü–æ—Å—Ç|–†–µ–¥–∞–∫—Ç–æ—Ä|–ù–æ–≤–æ—Å—Ç—å).*?:\s*', '', text, flags=re.IGNORECASE | re.DOTALL)
            return text
    except:
        return None

def run():
    search_query = "(YouTube OR TikTok OR Instagram OR VK OR Telegram OR –±–ª–æ–≥–µ—Ä OR —Å–∫–∞–Ω–¥–∞–ª OR —à–æ—É-–±–∏–∑–Ω–µ—Å OR –ø–æ–ª–∏—Ç–∏–∫–∞ OR –ß–ü OR –ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏–µ OR –ø–æ–≥–æ–¥–∞ OR –Ω–æ–≤–æ—Å—Ç–∏)"
    url = f"https://newsapi.org/v2/everything?q={search_query}&language=ru&sortBy=publishedAt&apiKey={NEWS_API_KEY}"
    
    try:
        articles = requests.get(url).json().get('articles', [])
    except: return

    posted_data = get_posted_data()
    random.shuffle(articles)

    for art in articles:
        link = art['url']
        title = art['title']
        clean_title = re.sub(r'[^\w\s]', '', title).lower().strip()
        
        if link in posted_data or clean_title in posted_data: continue
        
        raw_text = get_full_article(link)
        content = raw_text if (raw_text and len(raw_text) > 300) else art.get('description', "")
        if not content: continue

        final_text = rewrite_text(title, content)
        if not final_text or len(final_text) < 300: continue

        full_message = f"{final_text}\n\nüóû <b><a href='https://t.me/SUP_V_BotK'>–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ SUP_V_BotK</a></b>"

        try:
            if art.get('urlToImage'):
                bot.send_photo(CHANNEL_ID, art['urlToImage'])
            
            bot.send_message(CHANNEL_ID, full_message, parse_mode='HTML', disable_web_page_preview=True)
            
            save_posted_data(link, title)
            break
        except: continue

if __name__ == "__main__":
    run()
